{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Augment the literature data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Load libraries and modules\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from modelval import pairptl, network, trainer, dataset, data_aug_knn, perform_eval\n",
    "from modelval.ArbDataGen import arb_w_gen, data_Gen\n",
    "from modelval.spk_visu import spk_see, raster\n",
    "from modelval import gp_regressor\n",
    "from modelval import data_aug_gp\n",
    "from sklearn.model_selection import train_test_split\n",
    "from modelval.kernel import KernelGen\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "% matplotlib inline\n",
    "% load_ext autoreload\n",
    "% autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ptl_idx</th>\n",
       "      <th>pre_spk_num</th>\n",
       "      <th>pre_spk_freq</th>\n",
       "      <th>post_spk_num</th>\n",
       "      <th>post_spk_freq</th>\n",
       "      <th>ptl_occ</th>\n",
       "      <th>ptl_freq</th>\n",
       "      <th>dt1</th>\n",
       "      <th>dt2</th>\n",
       "      <th>dt3</th>\n",
       "      <th>dw_mean</th>\n",
       "      <th>dw_ste</th>\n",
       "      <th>train_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-102.898046</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.322590</td>\n",
       "      <td>0.0</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-75.579896</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.674768</td>\n",
       "      <td>0.0</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-80.871473</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-12.696449</td>\n",
       "      <td>0.0</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-67.562239</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.231446</td>\n",
       "      <td>0.0</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-63.553410</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.990216</td>\n",
       "      <td>0.0</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ptl_idx  pre_spk_num  pre_spk_freq  post_spk_num  post_spk_freq  ptl_occ  \\\n",
       "0        1            1             0             1              0       60   \n",
       "1        1            1             0             1              0       60   \n",
       "2        1            1             0             1              0       60   \n",
       "3        1            1             0             1              0       60   \n",
       "4        1            1             0             1              0       60   \n",
       "\n",
       "   ptl_freq         dt1  dt2  dt3    dw_mean  dw_ste  train_len  \n",
       "0       1.0 -102.898046  0.0    0  -1.322590     0.0         60  \n",
       "1       1.0  -75.579896  0.0    0   2.674768     0.0         60  \n",
       "2       1.0  -80.871473  0.0    0 -12.696449     0.0         60  \n",
       "3       1.0  -67.562239  0.0    0   0.231446     0.0         60  \n",
       "4       1.0  -63.553410  0.0    0  -0.990216     0.0         60  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data frame\n",
    "data = pd.read_csv('/src/Plasticity_Ker/data/kernel_training_data_auto.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Generate cv for training and validation data given the test fold\n",
    "data_gen_train, data_gen_vali, data_gen_test, y_train, y_vali, y_test = data_Gen(test_fold_num=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Initial validation mse=139.02353\n",
      "Global Step 0150 and Step 0150: validation mse=114.57407\n",
      "Updated min validation loss!Saving model...\n",
      "Global Step 0200 and Step 0200: validation mse=111.29293\n",
      "Updated min validation loss!Saving model...\n",
      "Global Step 0250 and Step 0250: validation mse=107.59901\n",
      "Updated min validation loss!Saving model...\n",
      "Global Step 0300 and Step 0300: validation mse=102.70110\n",
      "Updated min validation loss!Saving model...\n",
      "Global Step 0350 and Step 0350: validation mse=96.34505\n",
      "Updated min validation loss!Saving model...\n",
      "Global Step 0400 and Step 0400: validation mse=89.37564\n",
      "Updated min validation loss!Saving model...\n",
      "Global Step 0450 and Step 0450: validation mse=82.29892\n",
      "Updated min validation loss!Saving model...\n",
      "Global Step 0500 and Step 0500: validation mse=75.13187\n",
      "Updated min validation loss!Saving model...\n",
      "Global Step 0550 and Step 0550: validation mse=68.06936\n",
      "Updated min validation loss!Saving model...\n",
      "Global Step 0600 and Step 0600: validation mse=60.60105\n",
      "Updated min validation loss!Saving model...\n",
      "Global Step 0650 and Step 0650: validation mse=53.15817\n",
      "Updated min validation loss!Saving model...\n",
      "Global Step 0700 and Step 0700: validation mse=46.54750\n",
      "Updated min validation loss!Saving model...\n",
      "Global Step 0750 and Step 0750: validation mse=41.62143\n",
      "Updated min validation loss!Saving model...\n",
      "Global Step 0800 and Step 0800: validation mse=38.36749\n",
      "Updated min validation loss!Saving model...\n",
      "Global Step 0850 and Step 0850: validation mse=36.56540\n",
      "Updated min validation loss!Saving model...\n",
      "Global Step 0900 and Step 0900: validation mse=35.45667\n",
      "Updated min validation loss!Saving model...\n",
      "Global Step 0950 and Step 0950: validation mse=34.92738\n",
      "Updated min validation loss!Saving model...\n",
      "Global Step 1000 and Step 1000: validation mse=34.40392\n",
      "Updated min validation loss!Saving model...\n",
      "Global Step 1050 and Step 1050: validation mse=33.92629\n",
      "Updated min validation loss!Saving model...\n",
      "Global Step 1100 and Step 1100: validation mse=33.55590\n",
      "Updated min validation loss!Saving model...\n",
      "Global Step 1150 and Step 1150: validation mse=33.02924\n",
      "Updated min validation loss!Saving model...\n",
      "Global Step 1200 and Step 1200: validation mse=32.61084\n",
      "Updated min validation loss!Saving model...\n",
      "Global Step 1250 and Step 1250: validation mse=31.90753\n",
      "Updated min validation loss!Saving model...\n",
      "Global Step 1300 and Step 1300: validation mse=31.36494\n",
      "Updated min validation loss!Saving model...\n",
      "Global Step 1350 and Step 1350: validation mse=30.65997\n",
      "Updated min validation loss!Saving model...\n",
      "Global Step 1400 and Step 1400: validation mse=30.15704\n",
      "Updated min validation loss!Saving model...\n",
      "Global Step 1450 and Step 1450: validation mse=29.55985\n",
      "Updated min validation loss!Saving model...\n",
      "Global Step 1500 and Step 1500: validation mse=29.17297\n",
      "Updated min validation loss!Saving model...\n",
      "Global Step 1550 and Step 1550: validation mse=28.87887\n",
      "Updated min validation loss!Saving model...\n",
      "Global Step 1600 and Step 1600: validation mse=28.32393\n",
      "Updated min validation loss!Saving model...\n",
      "Global Step 1650 and Step 1650: validation mse=28.17773\n",
      "Updated min validation loss!Saving model...\n",
      "Global Step 1700 and Step 1700: validation mse=28.03654\n",
      "Updated min validation loss!Saving model...\n",
      "Global Step 1750 and Step 1750: validation mse=27.87634\n",
      "Updated min validation loss!Saving model...\n",
      "Global Step 1800 and Step 1800: validation mse=27.69825\n",
      "Updated min validation loss!Saving model...\n",
      "Global Step 1850 and Step 1850: validation mse=27.57192\n",
      "Updated min validation loss!Saving model...\n",
      "Global Step 1900 and Step 1900: validation mse=27.48865\n",
      "Updated min validation loss!Saving model...\n",
      "Global Step 1950 and Step 1950: validation mse=27.47340\n",
      "Updated min validation loss!Saving model...\n",
      "Global Step 2000 and Step 2000: validation mse=27.42553\n",
      "Updated min validation loss!Saving model...\n",
      "Global Step 2050 and Step 2050: validation mse=27.27509\n",
      "Updated min validation loss!Saving model...\n",
      "Global Step 2100 and Step 2100: validation mse=27.34937\n",
      "Global Step 2150 and Step 2150: validation mse=27.19714\n",
      "Updated min validation loss!Saving model...\n",
      "Global Step 2200 and Step 2200: validation mse=27.08579\n",
      "Updated min validation loss!Saving model...\n",
      "Global Step 2250 and Step 2250: validation mse=27.05753\n",
      "Updated min validation loss!Saving model...\n",
      "Global Step 2300 and Step 2300: validation mse=26.94202\n",
      "Updated min validation loss!Saving model...\n",
      "Global Step 2350 and Step 2350: validation mse=26.93231\n",
      "Updated min validation loss!Saving model...\n",
      "Global Step 2400 and Step 2400: validation mse=26.72620\n",
      "Updated min validation loss!Saving model...\n",
      "Global Step 2450 and Step 2450: validation mse=26.87943\n",
      "Global Step 2500 and Step 2500: validation mse=26.63653\n",
      "Updated min validation loss!Saving model...\n",
      "Global Step 2550 and Step 2550: validation mse=26.74135\n",
      "Global Step 2600 and Step 2600: validation mse=26.55601\n",
      "Updated min validation loss!Saving model...\n",
      "Global Step 2650 and Step 2650: validation mse=26.66363\n",
      "Global Step 2700 and Step 2700: validation mse=26.45253\n",
      "Updated min validation loss!Saving model...\n",
      "Global Step 2750 and Step 2750: validation mse=26.25781\n",
      "Updated min validation loss!Saving model...\n",
      "Global Step 2800 and Step 2800: validation mse=26.15268\n",
      "Updated min validation loss!Saving model...\n",
      "Global Step 2850 and Step 2850: validation mse=26.09050\n",
      "Updated min validation loss!Saving model...\n",
      "Global Step 2900 and Step 2900: validation mse=26.00485\n",
      "Updated min validation loss!Saving model...\n",
      "Global Step 2950 and Step 2950: validation mse=25.99145\n",
      "Updated min validation loss!Saving model...\n",
      "Global Step 3000 and Step 3000: validation mse=25.84890\n",
      "Updated min validation loss!Saving model...\n",
      "Global Step 3050 and Step 3050: validation mse=25.72614\n",
      "Updated min validation loss!Saving model...\n",
      "Global Step 3100 and Step 3100: validation mse=25.61126\n",
      "Updated min validation loss!Saving model...\n",
      "Global Step 3150 and Step 3150: validation mse=25.52346\n",
      "Updated min validation loss!Saving model...\n",
      "Global Step 3200 and Step 3200: validation mse=25.46633\n",
      "Updated min validation loss!Saving model...\n",
      "Global Step 3250 and Step 3250: validation mse=25.33591\n",
      "Updated min validation loss!Saving model...\n",
      "Global Step 3300 and Step 3300: validation mse=25.16590\n",
      "Updated min validation loss!Saving model...\n",
      "Global Step 3350 and Step 3350: validation mse=25.05286\n",
      "Updated min validation loss!Saving model...\n",
      "Global Step 3400 and Step 3400: validation mse=24.97817\n",
      "Updated min validation loss!Saving model...\n",
      "Global Step 3450 and Step 3450: validation mse=24.82457\n",
      "Updated min validation loss!Saving model...\n",
      "Global Step 3500 and Step 3500: validation mse=24.60612\n",
      "Updated min validation loss!Saving model...\n",
      "Global Step 3550 and Step 3550: validation mse=24.57502\n",
      "Updated min validation loss!Saving model...\n",
      "Global Step 3600 and Step 3600: validation mse=24.45304\n",
      "Updated min validation loss!Saving model...\n",
      "Global Step 3650 and Step 3650: validation mse=24.34221\n",
      "Updated min validation loss!Saving model...\n",
      "Global Step 3700 and Step 3700: validation mse=24.14923\n",
      "Updated min validation loss!Saving model...\n",
      "Global Step 3750 and Step 3750: validation mse=23.94927\n",
      "Updated min validation loss!Saving model...\n",
      "Global Step 3800 and Step 3800: validation mse=23.81792\n",
      "Updated min validation loss!Saving model...\n",
      "Global Step 3850 and Step 3850: validation mse=23.79777\n",
      "Updated min validation loss!Saving model...\n",
      "Global Step 3900 and Step 3900: validation mse=23.51095\n",
      "Updated min validation loss!Saving model...\n",
      "Global Step 3950 and Step 3950: validation mse=23.41940\n",
      "Updated min validation loss!Saving model...\n",
      "Global Step 4000 and Step 4000: validation mse=23.15704\n",
      "Updated min validation loss!Saving model...\n",
      "Global Step 4050 and Step 4050: validation mse=23.04694\n",
      "Updated min validation loss!Saving model...\n",
      "Global Step 4100 and Step 4100: validation mse=22.85442\n",
      "Updated min validation loss!Saving model...\n",
      "Global Step 4150 and Step 4150: validation mse=22.62025\n",
      "Updated min validation loss!Saving model...\n",
      "Global Step 4200 and Step 4200: validation mse=22.43734\n",
      "Updated min validation loss!Saving model...\n",
      "Global Step 4250 and Step 4250: validation mse=22.37780\n",
      "Updated min validation loss!Saving model...\n",
      "Global Step 4300 and Step 4300: validation mse=22.03274\n",
      "Updated min validation loss!Saving model...\n",
      "Global Step 4350 and Step 4350: validation mse=21.99155\n",
      "Updated min validation loss!Saving model...\n",
      "Global Step 4400 and Step 4400: validation mse=21.76851\n",
      "Updated min validation loss!Saving model...\n",
      "Global Step 4450 and Step 4450: validation mse=21.53853\n",
      "Updated min validation loss!Saving model...\n",
      "Global Step 4500 and Step 4500: validation mse=21.48651\n",
      "Updated min validation loss!Saving model...\n",
      "Global Step 4550 and Step 4550: validation mse=21.10321\n",
      "Updated min validation loss!Saving model...\n",
      "Global Step 4600 and Step 4600: validation mse=20.92441\n",
      "Updated min validation loss!Saving model...\n",
      "Global Step 4650 and Step 4650: validation mse=20.59516\n",
      "Updated min validation loss!Saving model...\n",
      "Global Step 4700 and Step 4700: validation mse=20.43472\n",
      "Updated min validation loss!Saving model...\n",
      "Global Step 4750 and Step 4750: validation mse=20.23327\n",
      "Updated min validation loss!Saving model...\n",
      "Global Step 4800 and Step 4800: validation mse=20.06874\n",
      "Updated min validation loss!Saving model...\n",
      "Global Step 4850 and Step 4850: validation mse=19.76218\n",
      "Updated min validation loss!Saving model...\n",
      "Global Step 4900 and Step 4900: validation mse=19.60329\n",
      "Updated min validation loss!Saving model...\n",
      "Global Step 4950 and Step 4950: validation mse=19.43161\n",
      "Updated min validation loss!Saving model...\n",
      "Global Step 5000 and Step 5000: validation mse=19.15888\n",
      "Updated min validation loss!Saving model...\n",
      "Global Step 5050 and Step 5050: validation mse=18.99138\n",
      "Updated min validation loss!Saving model...\n",
      "Global Step 5100 and Step 5100: validation mse=18.83130\n",
      "Updated min validation loss!Saving model...\n",
      "Global Step 5150 and Step 5150: validation mse=18.60718\n",
      "Updated min validation loss!Saving model...\n",
      "Global Step 5200 and Step 5200: validation mse=18.17818\n",
      "Updated min validation loss!Saving model...\n",
      "Global Step 5250 and Step 5250: validation mse=17.97196\n",
      "Updated min validation loss!Saving model...\n",
      "Global Step 5300 and Step 5300: validation mse=17.67524\n",
      "Updated min validation loss!Saving model...\n",
      "Global Step 5350 and Step 5350: validation mse=17.50133\n",
      "Updated min validation loss!Saving model...\n",
      "Global Step 5400 and Step 5400: validation mse=17.24507\n",
      "Updated min validation loss!Saving model...\n",
      "Global Step 5450 and Step 5450: validation mse=17.05804\n",
      "Updated min validation loss!Saving model...\n",
      "Global Step 5500 and Step 5500: validation mse=16.78859\n",
      "Updated min validation loss!Saving model...\n",
      "Global Step 5550 and Step 5550: validation mse=16.51765\n",
      "Updated min validation loss!Saving model...\n",
      "Global Step 5600 and Step 5600: validation mse=16.23374\n",
      "Updated min validation loss!Saving model...\n",
      "Global Step 5650 and Step 5650: validation mse=15.97648\n",
      "Updated min validation loss!Saving model...\n",
      "Global Step 5700 and Step 5700: validation mse=15.77735\n",
      "Updated min validation loss!Saving model...\n",
      "Global Step 5750 and Step 5750: validation mse=15.58566\n",
      "Updated min validation loss!Saving model...\n",
      "Global Step 5800 and Step 5800: validation mse=15.51044\n",
      "Updated min validation loss!Saving model...\n",
      "Global Step 5850 and Step 5850: validation mse=15.36298\n",
      "Updated min validation loss!Saving model...\n",
      "Global Step 5900 and Step 5900: validation mse=15.13278\n",
      "Updated min validation loss!Saving model...\n",
      "Global Step 5950 and Step 5950: validation mse=14.92620\n",
      "Updated min validation loss!Saving model...\n",
      "Global Step 6000 and Step 6000: validation mse=14.82515\n",
      "Updated min validation loss!Saving model...\n",
      "Global Step 6050 and Step 6050: validation mse=14.61019\n",
      "Updated min validation loss!Saving model...\n",
      "Global Step 6100 and Step 6100: validation mse=14.45659\n",
      "Updated min validation loss!Saving model...\n",
      "Global Step 6150 and Step 6150: validation mse=14.33185\n",
      "Updated min validation loss!Saving model...\n",
      "Global Step 6200 and Step 6200: validation mse=14.26934\n",
      "Updated min validation loss!Saving model...\n",
      "Global Step 6250 and Step 6250: validation mse=14.18832\n",
      "Updated min validation loss!Saving model...\n",
      "Global Step 6300 and Step 6300: validation mse=14.09337\n",
      "Updated min validation loss!Saving model...\n",
      "Global Step 6350 and Step 6350: validation mse=13.98786\n",
      "Updated min validation loss!Saving model...\n",
      "Global Step 6400 and Step 6400: validation mse=13.88019\n",
      "Updated min validation loss!Saving model...\n",
      "Global Step 6450 and Step 6450: validation mse=13.77785\n",
      "Updated min validation loss!Saving model...\n",
      "Global Step 6500 and Step 6500: validation mse=13.65798\n",
      "Updated min validation loss!Saving model...\n",
      "Global Step 6550 and Step 6550: validation mse=13.59807\n",
      "Updated min validation loss!Saving model...\n",
      "Global Step 6600 and Step 6600: validation mse=13.57416\n",
      "Updated min validation loss!Saving model...\n",
      "Global Step 6650 and Step 6650: validation mse=13.61561\n",
      "Global Step 6700 and Step 6700: validation mse=13.53016\n",
      "Updated min validation loss!Saving model...\n",
      "Global Step 6750 and Step 6750: validation mse=13.45375\n",
      "Updated min validation loss!Saving model...\n",
      "Global Step 6800 and Step 6800: validation mse=13.39976\n",
      "Updated min validation loss!Saving model...\n",
      "Global Step 6850 and Step 6850: validation mse=13.33289\n",
      "Updated min validation loss!Saving model...\n",
      "Global Step 6900 and Step 6900: validation mse=13.31078\n",
      "Updated min validation loss!Saving model...\n",
      "Global Step 6950 and Step 6950: validation mse=13.21517\n",
      "Updated min validation loss!Saving model...\n",
      "Global Step 7000 and Step 7000: validation mse=13.15406\n",
      "Updated min validation loss!Saving model...\n",
      "Global Step 7050 and Step 7050: validation mse=13.07547\n",
      "Updated min validation loss!Saving model...\n",
      "Global Step 7100 and Step 7100: validation mse=12.96539\n",
      "Updated min validation loss!Saving model...\n",
      "Global Step 7150 and Step 7150: validation mse=12.95545\n",
      "Updated min validation loss!Saving model...\n",
      "Global Step 7200 and Step 7200: validation mse=12.90672\n",
      "Updated min validation loss!Saving model...\n",
      "Global Step 7250 and Step 7250: validation mse=12.81053\n",
      "Updated min validation loss!Saving model...\n",
      "Global Step 7300 and Step 7300: validation mse=12.75329\n",
      "Updated min validation loss!Saving model...\n",
      "Global Step 7350 and Step 7350: validation mse=12.74079\n",
      "Updated min validation loss!Saving model...\n",
      "Global Step 7400 and Step 7400: validation mse=12.62805\n",
      "Updated min validation loss!Saving model...\n",
      "Global Step 7450 and Step 7450: validation mse=12.66941\n",
      "Global Step 7500 and Step 7500: validation mse=12.65141\n",
      "Global Step 7550 and Step 7550: validation mse=12.55542\n",
      "Updated min validation loss!Saving model...\n",
      "Global Step 7600 and Step 7600: validation mse=12.44118\n",
      "Updated min validation loss!Saving model...\n",
      "Global Step 7650 and Step 7650: validation mse=12.37527\n",
      "Updated min validation loss!Saving model...\n",
      "Global Step 7700 and Step 7700: validation mse=12.37439\n",
      "Updated min validation loss!Saving model...\n",
      "Global Step 7750 and Step 7750: validation mse=12.29723\n",
      "Updated min validation loss!Saving model...\n",
      "Global Step 7800 and Step 7800: validation mse=12.23360\n",
      "Updated min validation loss!Saving model...\n",
      "Global Step 7850 and Step 7850: validation mse=12.15606\n",
      "Updated min validation loss!Saving model...\n",
      "Global Step 7900 and Step 7900: validation mse=12.12239\n",
      "Updated min validation loss!Saving model...\n",
      "Global Step 7950 and Step 7950: validation mse=12.01974\n",
      "Updated min validation loss!Saving model...\n",
      "Global Step 8000 and Step 8000: validation mse=11.98855\n",
      "Updated min validation loss!Saving model...\n",
      "Global Step 8050 and Step 8050: validation mse=11.94055\n",
      "Updated min validation loss!Saving model...\n",
      "Global Step 8100 and Step 8100: validation mse=11.83965\n",
      "Updated min validation loss!Saving model...\n",
      "Global Step 8150 and Step 8150: validation mse=11.87907\n",
      "Global Step 8200 and Step 8200: validation mse=11.79167\n",
      "Updated min validation loss!Saving model...\n",
      "Global Step 8250 and Step 8250: validation mse=11.70864\n",
      "Updated min validation loss!Saving model...\n",
      "Global Step 8300 and Step 8300: validation mse=11.67038\n",
      "Updated min validation loss!Saving model...\n",
      "Global Step 8350 and Step 8350: validation mse=11.62290\n",
      "Updated min validation loss!Saving model...\n",
      "Global Step 8400 and Step 8400: validation mse=11.55435\n",
      "Updated min validation loss!Saving model...\n"
     ]
    }
   ],
   "source": [
    "# Visualize kernel\n",
    "vali_err = np.zeros(len(data_gen_train))\n",
    "for i in range(len(data_gen_train)):\n",
    "    ker_test = KernelGen()\n",
    "    \n",
    "    len_kernel = 101\n",
    "    len_trip = 151\n",
    "    ker_test = KernelGen(len_kernel=len_kernel, len_trip=len_trip)\n",
    "    \n",
    "    # Generat the spike trains and targets for STDP\n",
    "    data_hippo = data[data['ptl_idx']<5]\n",
    "    ptl_list = [1,2,3,4]\n",
    "    spk_len = int(data_hippo['train_len'].max() * 1000 / ker_test.reso_kernel)\n",
    "    if_noise = 1\n",
    "    aug_times = [1,1,1,1]\n",
    "    spk_pairs_train, targets_train = arb_w_gen(df=data_gen_train[i], ptl_list=ptl_list, targets=y_train[i], if_noise=if_noise, spk_len=spk_len, kernel=ker_test, net_type='triplet', aug_times=aug_times, seed=723)\n",
    "    spk_pairs_vali, targets_vali = arb_w_gen(df=data_gen_vali[i], ptl_list=ptl_list, targets=y_vali[i], if_noise=if_noise, spk_len=spk_len, kernel=ker_test, net_type='triplet', aug_times=aug_times, seed=606)\n",
    "    \n",
    "    # Create the network\n",
    "    ground_truth_init = 0\n",
    "    reg_scale=(10,50,100,200)\n",
    "    init_seed=(4,5,6,7,8)\n",
    "\n",
    "    toy_data_net = network.TripNet(kernel=ker_test, ground_truth_init=ground_truth_init, reg_scale=reg_scale, n_input=spk_pairs_train.shape[1])\n",
    "    \n",
    "    # Create the trainer\n",
    "    save_dir= '/src/Plasticity_Ker/model/Trip_ptl1_4_real_aug_gp_mean_noise_alpha1_alpha3_10_long_post_post_diff_bias' + 'cv' + str(i)\n",
    "    toy_net_trainer = trainer.Trainer(toy_data_net.mse, toy_data_net.loss, input_name=toy_data_net.inputs, target_name=toy_data_net.target, save_dir=save_dir, optimizer_config={'learning_rate': toy_data_net.lr})\n",
    "    \n",
    "    # Package the data\n",
    "    train_data = dataset.Dataset(spk_pairs_train, targets_train)\n",
    "    vali_data = dataset.Dataset(spk_pairs_vali, targets_vali)\n",
    "    \n",
    "    # Learn the kernel from random initialization\n",
    "    learning_rate = 0.001\n",
    "    iterations = 5\n",
    "    min_error = -1\n",
    "    for _ in range(iterations):\n",
    "        mini_vali_loss = toy_net_trainer.train(train_data, vali_data, batch_size=128, min_error=min_error, feed_dict={toy_data_net.lr: learning_rate})\n",
    "        learning_rate = learning_rate/3\n",
    " \n",
    "    vali_err[i] = mini_vali_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "toy_net_trainer.restore_best()\n",
    "w_pre = toy_net_trainer.evaluate(ops=toy_data_net.kernel_pre)\n",
    "w_post = toy_net_trainer.evaluate(ops=toy_data_net.kernel_post)\n",
    "w_post_post = toy_net_trainer.evaluate(ops=toy_data_net.kernel_post_post)\n",
    "fc_w = toy_net_trainer.evaluate(ops=toy_data_net.fc_w)\n",
    "bias = toy_net_trainer.evaluate(ops=toy_data_net.bias)\n",
    "scaler = toy_net_trainer.evaluate(ops=toy_data_net.scaler)\n",
    "\n",
    "plt.plot(-1*w_pre, label='ker_pre_trained')\n",
    "\n",
    "plt.plot(-1*w_post, label='ker_post_trained')\n",
    "plt.plot(-1*w_post_post, label='ker_post_post_trained')\n",
    "plt.legend()\n",
    "print([fc_w, bias, scaler])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Test effect of smoothed kernel\n",
    "w_pre_sm = w_pre\n",
    "w_post_sm = w_post \n",
    "w_post_post_sm = w_post_post\n",
    "w_pre_sm[:51] = data_aug_gp.smooth(w_pre[:51], width=10)\n",
    "w_post_sm[:49] = data_aug_gp.smooth(w_post[:49], width=10)\n",
    "w_post_post_sm[:100] = data_aug_gp.smooth(w_post_post[:100], width=5)\n",
    "\n",
    "plt.plot(-1 * w_pre_sm)\n",
    "plt.plot(-1 * w_post_sm)\n",
    "plt.plot(-1*w_post_post_sm)\n",
    "\n",
    "ker_test.kernel_pre = w_pre_sm\n",
    "ker_test.kernel_post = w_post_sm\n",
    "ker_test.kernel_post_post= w_post_post_sm\n",
    "ker_test.kernel_scale = fc_w\n",
    "ker_test.bias = bias\n",
    "ker_test.scale = scaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "Compare the target and prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Updated the kernel as trained kernel\n",
    "ker_test.kernel_pre = w_pre\n",
    "ker_test.kernel_post = w_post\n",
    "ker_test.kernel_post_post= w_post_post\n",
    "ker_test.kernel_scale = fc_w\n",
    "ker_test.bias = bias\n",
    "ker_test.scale = scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Generate training predictions\n",
    "spk_len = int(data['train_len'].max() * 1000 / ker_test.reso_kernel)\n",
    "_, predictions_train = arb_w_gen(spk_pairs=spk_pairs_train, spk_len=spk_len, kernel=ker_test, net_type='triplet')\n",
    "\n",
    "ptl_len = np.array([160,3,160,3])\n",
    "rep_time = np.array([1,1,1,1])\n",
    "ptl_len, targets_out, predictions_out = data_aug_knn.target_pred_gen(targets_train, predictions_train, ptl_len, rep_time)\n",
    "\n",
    "# Calculate the total sum of squares\n",
    "R2 = 1 - np.sum(np.square(predictions_train-targets_train))/(np.square(np.std(targets_train))*(len(targets_train)-1))\n",
    "\n",
    "plt.plot(np.linspace(-30,50,80), np.linspace(-30,50,80),'k--')\n",
    "ptl_type = ['stdp', 'trip1', 'quad','trip2']\n",
    "for i in range(len(ptl_len)):\n",
    "    plt.plot(targets_out[i], predictions_out[i],'o', label=ptl_type[i])\n",
    "\n",
    "plt.title('Training data (R2=%0.2f)'%(R2))\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Generate validation predictions\n",
    "spk_len = int(data['train_len'].max() * 1000 / ker_test.reso_kernel)\n",
    "_, predictions_vali = arb_w_gen(spk_pairs=spk_pairs_vali, spk_len=spk_len, kernel=ker_test, net_type='triplet')\n",
    "\n",
    "ptl_len = np.array([40,1,40,1])\n",
    "rep_time = np.array([1,1,1,1])\n",
    "ptl_len, targets_out, predictions_out = data_aug_knn.target_pred_gen(targets_vali, predictions_vali, ptl_len, rep_time)\n",
    "\n",
    "# Calculate the total sum of squares\n",
    "R2 = 1 - np.sum(np.square(predictions_vali-targets_vali))/(np.square(np.std(targets_vali))*(len(targets_vali)-1))\n",
    "corr = np.sqrt(R2)\n",
    "\n",
    "plt.plot(np.linspace(-30,50,80), np.linspace(-30,50,80),'k--')\n",
    "ptl_type = ['stdp', 'trip1', 'quad','trip2']\n",
    "for i in range(len(ptl_len)):\n",
    "    plt.plot(targets_out[i], predictions_out[i],'o', label=ptl_type[i])\n",
    "\n",
    "plt.title('Validation data (R2=%0.2f)'%(R2))\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Generat the spike trains and targets for STDP\n",
    "data3 = data[data['ptl_idx']==3]\n",
    "ptl_list = [1,2,3,4]\n",
    "spk_len = int(data3['train_len'].max() * 1000 / ker_test.reso_kernel)\n",
    "if_noise = 0\n",
    "aug_times = [1,1,1,1]\n",
    "spk_pairs_test, targets_test = arb_w_gen(df=data_gen_test, ptl_list=ptl_list, targets=y_test, if_noise=if_noise, spk_len=spk_len, kernel=ker_test, net_type='triplet', aug_times=aug_times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Generate test predictions\n",
    "spk_len = int(data['train_len'].max() * 1000 / ker_test.reso_kernel)\n",
    "_, predictions_test = arb_w_gen(spk_pairs=spk_pairs_test, spk_len=spk_len, kernel=ker_test, net_type='triplet')\n",
    "\n",
    "ptl_len = np.array([12,7,12,4])\n",
    "rep_time = np.array([1,1,1,1])\n",
    "ptl_len, targets_out, predictions_out = data_aug_knn.target_pred_gen(targets_test, predictions_test, ptl_len, rep_time)\n",
    "\n",
    "# Calculate the total sum of squares\n",
    "R2 = 1 - np.sum(np.square(predictions_test-targets_test))/(np.square(np.std(targets_test))*(len(targets_test)-1))\n",
    "corr = np.sqrt(R2)\n",
    "\n",
    "plt.plot(np.linspace(-30,50,80), np.linspace(-30,50,80),'k--')\n",
    "ptl_type = ['stdp', 'trip1', 'quad','trip2']\n",
    "for i in range(len(ptl_len)):\n",
    "    plt.plot(targets_out[i], predictions_out[i],'o', label=ptl_type[i])\n",
    "\n",
    "plt.title('Testing data (R2=%0.2f)'%(R2))\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
